<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Information, Inference and Machine Learning Group at University College London | Members</title>

  <!-- Bootstrap core CSS -->
  <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="../css/business-frontpage.css" rel="stylesheet">

  <script src="https://kit.fontawesome.com/f071da7bc5.js"></script>

  <link rel='icon' href='../imgs/favicon.ico' type='image/x-icon' sizes="16x16" />


  <script src="https://code.jquery.com/jquery-3.3.1.js" integrity="sha256-2Kok7MbOyxpgUVvAk/HJ2jigOSYS2auK4Pfzbm7uH60="
    crossorigin="anonymous">
    </script>
  <script src="../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</head>

<script>
  $(function () {
    $("#footer").load("../footer.html");
    $("#nav").load("header.html");
  });
</script>

<body>

  <!-- Navigation -->
  <div id="nav"></div>


  <!-- Page Content -->
  <div class="container" style="padding: 20px;">
    <div class="col-lg-12">

      <div class="row">
        <div class="col-lg-12">
          <h2>Martin Ferianc</h2>
          <h3>First-year PhD Student</h3>
          <hr>
        </div>
      </div>
      <div class="row">
        <div class="col-md-4 text-center">
          <img class="member-image img-fluid" src="ferianc/ferianc.jpg" alt="">
          <h4>Contact</h4>
          <hr>

          <ul class="list-inline social-buttons">
            <li class="list-inline-item">
              <a target="_blank" href="https://twitter.com/FeriancMartin">
                <i class="fab fa-twitter"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a target="_blank" href="https://www.linkedin.com/in/feriancmartin/">
                <i class="fab fa-linkedin"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a target="_blank" href="https://github.com/martinferianc">
                <i class="fab fa-github"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a target="_blank" href="https://scholar.google.com/citations?user=itcRKZQAAAAJ&hl=en">
                <i class="fas fa-graduation-cap"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a target="_blank" href="mailto:ferianc.martin@gmail.com">
                <i class="fas fa-envelope"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a target="_blank" href="www.ferianc.eu">
                <i class="fas fa-globe"></i>
              </a>
            </li>
          </ul>
          <hr>
          <h4>Where to Find Me</h4>
          <hr>
          <address>
            Mallet Place Engineering Building
            <br>Torrington Place
            <br>London WC1E 7JE
            <br>United Kingdom
            <br>
          </address>
          <h4>My Feed</h4>
          <hr>
          <a class="twitter-timeline" data-height="400"
            href="https://twitter.com/FeriancMartin?ref_src=twsrc%5Etfw">Tweets by Martin</a>
          <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

        </div>
        <div class="col-md-8 publication-text">
          <h4>Research Interests</h4>
          <hr>
          <p>AutoML, Bayesian neural networks, Metalearning and Deep Learning</p>
          <h4>About</h4>
          <hr>
          <p>Martin Ferianc is a PhD candidate in the Department of Electronic and Electrical Engineering at University
            College London. His research interests include AutoML, Bayesian neural networks, Metalearning and Deep
            Learning
            . Martin has an MEng in Electronic and Information Engineering from Imperial College London.
          </p>
          <h4>Publications</h4>
          <hr>
          <div class="row">
            <div class="col-md-12 mb-5">
              <h5>2020</h5>
              <hr>
            </div>
          </div>
          <div class="row">
            <div class="col-md-12">
              <div id="ferianc2019arc" class="row publication">
                <div class="col-md-4">
                  <a href="https://arxiv.org/abs/2002.00190" target="_blank"><img class="img-fluid"
                      src="ferianc/ferianc2020arc.png" alt=""></a>
                </div>
                <div class="col-md-8 publication-text">
                  <strong>Title:</strong> Improving Performance Estimation for FPGA-based Accelerators for Convolutional
                  Neural Networks<br>
                  <strong>Authors:</strong> M. Ferianc, H. Fan, R.S.W. Chu, J. Stano, W. Luk<br>
                  <strong>Journal/Conference:</strong> International Symposium on Applied Reconfigurable Computing
                  (ARC)<br>
                  <p> <strong>Abstract:</strong> Field-programmable gate array (FPGA) based accelerators are being
                    widely used for acceleration of convolutional neural networks (CNNs) due to their potential in
                    improving the performance and reconfigurability for specific application instances. To determine the
                    optimal configuration of an FPGA-based accelerator, it is necessary to explore the design space and
                    an accurate performance prediction plays an important role during the exploration. This work
                    introduces a novel method for fast and accurate estimation of latency based on a Gaussian process
                    parametrised by an analytic approximation and coupled with runtime data. The experiments conducted
                    on three different CNNs on an FPGA-based accelerator on Intel Arria 10 GX 1150 demonstrated a 30.7%
                    improvement in accuracy with respect to the mean absolute error in comparison to a standard analytic
                    method in leave-one-out cross-validation.</p>
                  <a href="https://arxiv.org/abs/2002.00190" target="_blank"><strong><i class="fas fa-link"></i>
                      Link</strong></a>
                </div>
              </div>
            </div>
          </div>
          <div class="row">
            <div class="col-md-12 mb-5">
              <h5>2019</h5>
              <hr>
            </div>
          </div>
          <div class="row">
            <div class="col-md-12">
              <div id="ferianc2020fpt" class="row publication">
                <div class="col-md-4">
                  <a href="https://ieeexplore.ieee.org/abstract/document/8977902" target="_blank"><img class="img-fluid"
                      src="ferianc/ferianc2020fpt.png" alt=""></a>
                </div>
                <div class="col-md-8 publication-text">
                  <strong>Title:</strong> Static Block Floating-Point Quantization for Convolutional Neural Networks on FPGA<br>
                  <strong>Authors:</strong> H. Fan, G. Wang, M. Ferianc, X. Niu and W Luk<br>
                  <strong>Journal/Conference:</strong> International Conference on Field-Programmable Technology (ICFPT)<br>
                  <p> <strong>Abstract:</strong> Convolutional neural networks (CNNs) have been widely applied in various computer vision and speech processing
                  applications. However, the algorithmic complexity of CNNs hinders their deployment in embedded systems with limited
                  memory and computational resources. This paper proposes static block floating-point (BFP) quantization, an effective
                  approach involving Kullback-Leibler divergence, to determine the static shared exponents. Without need for retraining,
                  the proposed approach is able to quantize CNNs to 8 bits with negligible accuracy loss. An FPGA-based hardware design
                  with static BFP quantization is also proposed. Compared with 8-bit integer linear quantization, our experiments show
                  that the hardware kernel based on static BFP quantization can achieve over 50% reduction in logic resources on an FPGA.
                  Based on static BFP quantization, a tool implemented in the PyTorch framework is developed, which can automatically
                  generate optimised configuration according to user requirements for given CNN models, where the entire optimization
                  process takes only a few minutes on an Intel Xeon Silver 4110 CPU.</p>
                  <a href="https://ieeexplore.ieee.org/abstract/document/8977902" target="_blank"><strong><i class="fas fa-link"></i>
                      Link</strong></a>
                </div>
              </div>
            </div>
          </div>
          <div class="row">
            <div class="col-md-12">
              <div id="ferianc2019asap" class="row publication">
                <div class="col-md-4">
                  <a href="https://ieeexplore.ieee.org/abstract/document/8825127" target="_blank"><img class="img-fluid"
                      src="ferianc/ferianc2019asap.png" alt=""></a>
                </div>
                <div class="col-md-8 publication-text">
                  <strong>Title:</strong> F-E3D: FPGA-based Acceleration of an Efficient 3D Convolutional Neural Network
                  for Human Action Recognition<br>
                  <strong>Authors:</strong> H. Fan, C. Luo, C. Zheng, M. Ferianc, Z. Que, S. Liu, X. Niu, W. Luk<br>
                  <strong>Journal/Conference:</strong> International Conference on Application-specific Systems,
                  Architectures and Processors (ASAP)<br>
                  <p> <strong>Abstract:</strong> Three-dimensional convolutional neural networks (3D CNNs) have
                    demonstrated their outstanding classification accuracy for human action recognition (HAR). However,
                    the large number of computations and parameters in 3D CNNs limits their deployability in real-life
                    applications. To address this challenge, this paper adopts an algorithm-hardware co-design method by
                    proposing an efficient 3D CNN building unit called 3D-1 bottleneck residual block (3D-1 BRB) at the
                    algorithm level, and a corresponding FPGA-based hardware architecture called F-E3D at the hardware
                    level. Based on 3D-1 BRB, a novel 3D CNN model called E3DNet is developed, which achieves nearly 37
                    times reduction in model size and 5% improvement in accuracy compared to standard 3D CNNs on the
                    UCF101 dataset. Together with several hardware optimizations, including 3D fused BRB, online
                    blocking and kernel reuse, the proposed F-E3D is nearly 13 times faster than a previous FPGA design
                    for 3D CNNs, with performance and accuracy comparable to other state-of-the-art 3D CNN models on GPU
                    platforms while requiring only 7% of their energy consumption.</p>
                  <a href="https://ieeexplore.ieee.org/abstract/document/8825127" target="_blank"><strong><i
                        class="fas fa-link"></i> Link</strong></a>
                </div>
              </div>
            </div>
          </div>
          <div class="row">
            <div class="col-md-12 mb-5">
              <h5>2018</h5>
              <hr>
            </div>
          </div>
          <div class="row">
            <div class="col-md-12">
              <div id="ferianc2018fpt" class="row publication">
                <div class="col-md-4">
                  <a href="https://ieeexplore.ieee.org/abstract/document/8742299/" target="_blank"><img
                      class="img-fluid" src="ferianc/ferianc2019fpt.png" alt=""></a>
                </div>
                <div class="col-md-8 publication-text">
                  <strong>Title:</strong> A Real-Time Object Detection Accelerator with Compressed SSDLite on FPGA<br>
                  <strong>Authors:</strong> H. Fan, S. Liu, M. Ferianc, HC. Ng, Z. Que, S. Liu, X. Niu, W. Luk<br>
                  <strong>Journal/Conference:</strong> International Conference on Field-Programmable Technology
                  (FPT)<br>
                  <p> <strong>Abstract:</strong> TConvolutional neural network (CNN)-based object detection has been
                    widely employed in various applications such as autonomous driving and intelligent video
                    surveillance. However, the computational complexity of conventional convolution hinders its
                    application in embedded systems. Recently, a mobile-friendly CNN model SSDLite-MobileNetV2
                    (SSDLiteM2) has been proposed for object detection. This model consists of a novel layer called
                    bottleneck residual block (BRB). Although SSDLiteM2 contains far fewer parameters and computations
                    than conventional CNN models, its performance on embedded devices still cannot meet the requirements
                    of real-time processing. This paper proposes a novel FPGA-based architecture for SSDLiteM2 in
                    combination with hardware optimizations including fused BRB, processing element (PE) sharing and
                    load-balanced channel pruning. Moreover, a novel quantization scheme called partial quantization has
                    been developed, which partially quantizes SSDLiteM2 to 8 bits with only 1.8% accuracy loss.
                    Experiments show that the proposed design on a Xilinx ZC706 device can achieve up to 65 frames per
                    second with 20.3 mean average precision on the COCO dataset.</p>
                  <a href="https://ieeexplore.ieee.org/abstract/document/8742299/" target="_blank"><strong><i
                        class="fas fa-link"></i> Link</strong></a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

  </div>
  <!-- /.container -->

  <!-- Footer -->
  <div id="footer">
  </div>

</body>

</html>